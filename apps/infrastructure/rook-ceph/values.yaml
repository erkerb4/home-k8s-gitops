rook-ceph:
  csi:
    provisionerTolerations:
      - key: workload
        value: thor
        operator: Equal
        effect: NoSchedule
    pluginTolerations:
      - key: workload
        value: thor
        operator: Equal
        effect: NoSchedule
  resources:
    limits:
      cpu: 1250m
      memory: 768Mi
    requests:
      cpu: 125m
      memory: 256Mi
rook-ceph-cluster:
  toolbox:
    enabled: true
  cephClusterSpec:
    continueUpgradeAfterChecksEvenIfNotHealthy: true
    dashboard:
      ssl: false
    crashCollector:
      disable: true
      daysToRetain: 14
    storage:
      useAllNodes: false
      useAllDevices: false
      nodes:
        - name: "arcus"
          devices:
            - name: "nvme0n1p5"
              config:
                deviceClass: nvme
                metadataDevice: "/dev/nvme0n1p4"
            - name: "sda2"
              config:
                deviceClass: ssd
                metadataDevice: "/dev/sda1"
        - name: "cirrus"
          devices:
            - name: "nvme0n1p5"
              config:
                deviceClass: nvme
                metadataDevice: "/dev/nvme0n1p4"
            - name: "sda2"
              config:
                deviceClass: ssd
                metadataDevice: "/dev/sda1"
        - name: "intortus"
          devices:
            - name: "nvme0n1p5"
              config:
                deviceClass: nvme
                metadataDevice: "/dev/nvme0n1p4"
            - name: "sda2"
              config:
                deviceClass: ssd
                metadataDevice: "/dev/sda1"
  ingress:
    dashboard:
      host:
        name: ceph.xtr.pub
        path: "/"
      tls:
        - hosts:
          - ceph.xtr.pub
          secretName: tls-secret
      annotations:
        traefik.ingress.kubernetes.io/router.entrypoints: websecure
        cert-manager.io/cluster-issuer: le-prod

  cephBlockPoolsVolumeSnapshotClass:
    enabled: true
    name: ec-block
    isDefault: true

  cephFileSystems:
    - name: fs-silver-r1
      spec:
        metadataPool:
          deviceClass: ssd
          replicated:
            size: 1
        dataPools:
          - failureDomain: host
            replicated:
              size: 1
            name: data1
        metadataServer:
          activeCount: 1
          activeStandby: true
          priorityClassName: system-cluster-critical
          placement:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                  - key: app.kubernetes.io/part-of
                    operator: In
                    values:
                    - fs-silver-r1
                topologyKey: kubernetes.io/hostname
          resources:
            limits:
              cpu: "2"
              memory: "4Gi"
            requests:
              cpu: "500m"
              memory: "4Gi"
      storageClass:
        enabled: true
        isDefault: false
        name: fs-silver-r1
        pool: data1
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        volumeBindingMode: "Immediate"
        mountOptions: []
        parameters:
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
          csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/fstype: ext4
    # - name: fs-gold-r1
    #   spec:
    #     metadataPool:
    #       deviceClass: nvme
    #       replicated:
    #         size: 1
    #     dataPools:
    #       - failureDomain: host
    #         replicated:
    #           size: 1
    #         name: data0
    #     metadataServer:
    #       activeCount: 1
    #       activeStandby: false
    #       priorityClassName: system-cluster-critical
    #       placement:
    #         podAntiAffinity:
    #           requiredDuringSchedulingIgnoredDuringExecution:
    #           - labelSelector:
    #               matchExpressions:
    #               - key: app.kubernetes.io/part-of
    #                 operator: In
    #                 values:
    #                 - fs-gold-r1
    #             topologyKey: kubernetes.io/hostname
    #       resources:
    #         limits:
    #           cpu: "2"
    #           memory: "4Gi"
    #         requests:
    #           cpu: "500m"
    #           memory: "4Gi"
    #   storageClass:
    #     enabled: true
    #     isDefault: false
    #     name: fs-gold-r1
    #     pool: data0
    #     reclaimPolicy: Delete
    #     allowVolumeExpansion: true
    #     volumeBindingMode: "Immediate"
    #     mountOptions: []
    #     parameters:
    #       csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
    #       csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
    #       csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
    #       csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
    #       csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
    #       csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"
    #       csi.storage.k8s.io/fstype: ext4

  cephFileSystemVolumeSnapshotClass:
    enabled: true
    name: fs
    isDefault: false
    deletionPolicy: Delete
    annotations: {}
    labels: {}
    # see https://rook.io/docs/rook/v1.10/Storage-Configuration/Ceph-CSI/ceph-csi-snapshot/#cephfs-snapshots for available configuration
    parameters: {}

  cephObjectStores: {}
  ## StorageClass for cephECBlookPool
  ## does not render
  cephECBlockPools: {}

  cephBlockPools:
    - name: ec-silver-r1
      spec:
        failureDomain: host
        deviceClass: ssd
        replicated:
          size: 1
        # enableRBDStats: true
      storageClass:
        enabled: true
        name: ec-silver-r1
        isDefault: false
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        volumeBindingMode: "Immediate"
        parameters:
          imageFormat: "2"
          imageFeatures: layering
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/fstype: ext4
    - name: ec-gold-r1
      spec:
        failureDomain: host
        deviceClass: nvme
        replicated:
          size: 1
        # enableRBDStats: true
      storageClass:
        enabled: true
        name: ec-gold-r1
        isDefault: false
        reclaimPolicy: Delete
        allowVolumeExpansion: true
        volumeBindingMode: "Immediate"
        parameters:
          imageFormat: "2"
          imageFeatures: layering
          csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
          csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
          csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"
          csi.storage.k8s.io/fstype: ext4

operatorNamespace: rook-ceph
cephECBlockPoolz:
  - name: ec-silver
    spec:
      metadataPool:
        replicated:
          size: 2
      dataPool:
        failureDomain: osd
        erasureCoded:
          dataChunks: 2
          codingChunks: 1
        deviceClass: ssd
    storageClass:
      name:  ec-silver
      enabled: true
      isDefault: true
      provisioner: "rook-ceph.rbd.csi.ceph.com"
      allowVolumeExpansion: true
      reclaimPolicy: Delete
    parameters:
      clusterID: rook-ceph
      imageFormat: "2"
      imageFeatures: layering
  - name: ec-gold
    spec:
      metadataPool:
        replicated:
          size: 2
      dataPool:
        failureDomain: osd
        erasureCoded:
          dataChunks: 2
          codingChunks: 1
        deviceClass: nvme
    parameters:
      clusterID: rook-ceph
      imageFormat: "2"
      imageFeatures: layering
    storageClass:
      provisioner: "rook-ceph.rbd.csi.ceph.com"
      enabled: true
      name:  ec-gold
      isDefault: false
      allowVolumeExpansion: true
      reclaimPolicy: Delete
